# Explorar os conceitos básicos da análise em larga escala

## Descrever uma arquitetura de data warehousing
Ingestão e processamento de dados – os dados de um ou mais armazenamentos de dados transacionais, arquivos, fluxos em tempo real ou outras fontes são carregados em um data lake ou um data warehouse. A operação de carregamento geralmente envolve um processo de ETL (extração, transformação e carregamento) ou ELT (extração, carregamento e transformação) no qual os dados são limpos, filtrados e reestruturados para análise. Em processos de ETL, os dados são transformados antes de serem carregados em um armazenamento analítico, enquanto em um processo de ELT eles são copiados para o armazenamento e depois transformados. De qualquer forma, a estrutura de dados resultante é otimizada para consultas analíticas. O processamento de dados geralmente é executado por sistemas distribuídos que podem processar grandes volumes de dados em paralelo usando clusters de vários nós. A ingestão de dados inclui o processamento em lote de dados estáticos e o processamento em tempo real de dados de streaming.

Armazenamento de dados analíticos – os armazenamentos de dados para análise em grande escala incluem data warehouses relacionais, data lakes baseados em sistema de arquivos e arquiteturas híbridas que combinam recursos de data warehouses e data lakes (às vezes chamados de data lakehouses ou bancos de dados lake). Discutiremos isso em mais detalhes posteriormente.

Modelo de dados analíticos – embora analistas de dados e cientistas de dados possam trabalhar com os dados diretamente no armazenamento de dados analíticos, é comum criar um ou mais modelos de dados que agregam previamente os dados para facilitar a produção de relatórios, dashboards e visualizações interativas. Geralmente, esses modelos de dados são descritos como cubos, nos quais valores de dados numéricos são agregados em uma ou mais dimensões (por exemplo, para determinar o total de vendas por produto e região). O modelo encapsula as relações entre valores de dados e entidades dimensionais para dar suporte à análise de "drill up/drill down".

Visualização de dados – os analistas de dados consomem dados de modelos analíticos e diretamente de repositórios analíticos para criar relatórios, dashboards e outras visualizações. Além disso, os usuários em uma organização que talvez não sejam profissionais de tecnologia podem executar relatórios e análise de dados por autoatendimento. As visualizações dos dados mostram tendências, comparações e KPIs (indicadores chave de desempenho) para uma empresa ou outra organização e podem assumir a forma de relatórios impressos, grafos e gráficos em documentos ou apresentações de PowerPoint, dashboards baseados na Web e ambientes interativos nos quais os usuários podem explorar os dados visualmente.

## Explorar os pipelines de ingestão de dados

No Azure, a ingestão de dados em larga escala é melhor implementada criando pipelines que orquestram processos ETL. Você pode *criar e executar pipelines usando o Azure Data Factory* ou pode *usar a funcionalidade de pipeline no Microsoft Fabric se quiser gerenciar todos os componentes da solução de data warehousing em um workspace unificado*.

Em ambos os casos, os pipelines consistem em uma ou mais atividades que processam dados. Um conjunto de dados de entrada fornece os dados de origem, e as atividades podem ser definidas como um fluxo de dados que manipula de os dados maneira incremental até que um conjunto de dados de saída seja produzido. Os pipelines usam serviços vinculados para carregar e processar dados, permitindo que você use a tecnologia certa para cada etapa do fluxo de trabalho. 

Por exemplo, você pode usar um serviço vinculado ao Armazenamento de Blobs do Azure para ingerir o conjunto de dados de entrada e, em seguida, usar serviços como o Banco de Dados SQL do Azure para executar um procedimento armazenado que procura valores de dados relacionados, antes de executar uma tarefa de processamento de dados no Azure Databricks ou aplicar lógica personalizada usando uma Função do Azure. 

Por fim, você pode salvar o conjunto de dados de saída em um serviço vinculado, como o Microsoft Fabric. Os pipelines também podem incluir algumas atividades internas, que não exigem um serviço vinculado.

## Explorar os armazenamento de dados analíticos

### Data warehouse
Um data warehouse é um banco de dados relacional no qual os dados são armazenados em um esquema otimizado para análise de dados em vez de cargas de trabalho transacionais. Normalmente, os dados de um armazenamento transacional são transformados em um esquema no qual os valores numéricos são armazenados em tabelas de fatos centrais, que estão relacionadas a uma ou mais tabelas de dimensões que representam entidades pelas quais os dados podem ser agregados. Por exemplo, uma tabela de fatos pode conter dados de pedido de vendas, que podem ser agregados por cliente, produto, loja e dimensões de tempo (permitindo que você, por exemplo, encontre facilmente a receita total mensal de vendas por produto para cada loja). Esse tipo de esquema de tabela de fatos e dimensões é chamado de esquema em estrela; embora geralmente seja estendido para um esquema floco de neve adicionando outras tabelas relacionadas às tabelas de dimensões para representar hierarquias dimensionais (por exemplo, o produto pode estar relacionado a categorias de produtos). Um data warehouse é uma ótima opção quando você tem dados transacionais que podem ser organizados em um esquema estruturado de tabelas e deseja usar o SQL para consultá-los.

### Data lake
Um data lake é um armazenamento de arquivos, geralmente em um sistema de arquivos distribuído para acesso a dados de alto desempenho. Tecnologias como Spark ou Hadoop geralmente são usadas para processar consultas nos arquivos armazenados e retornar dados para relatórios e análises. Esses sistemas geralmente aplicam uma abordagem de esquema no ato da leitura para definir esquemas tabulares em arquivos de dados semiestruturados no ponto em que os dados são lidos para análise, sem aplicar restrições quando eles são armazenados. Os data lakes são ótimos para dar suporte a uma combinação de dados estruturados, semiestruturados e até mesmo não estruturados que você deseja analisar sem a necessidade de imposição de esquema quando os dados são gravados no repositório.

### Abordagens híbridas
Abordagem híbrida que combina recursos de data lakes e data warehouses em um data lakehouse. Os dados brutos são armazenados como arquivos em um data lake, e os pontos de extremidade de análise SQL do Microsoft Fabric os expõem como tabelas, que podem ser consultadas usando SQL. Quando você cria um Lakehouse com o *Microsoft Fabric*, um ponto de extremidade de análise SQL é criado automaticamente. Os data lakehouses são uma abordagem relativamente nova em sistemas baseados em Spark e são habilitados por meio de tecnologias como o Delta Lake; que adiciona recursos de armazenamento relacional ao Spark, para que você possa definir tabelas que impõem esquemas e consistência transacional, dão suporte a fontes de dados carregadas em lote e streaming e fornecem uma API de SQL para consulta.

## Serviços do Azure para repositórios analíticos

### O Microsoft Fabric
Uma solução unificada e completa para análise de dados em larga escala. Ele reúne várias tecnologias e funcionalidades, permitindo que você combine a integridade e a confiabilidade de dados de um data warehouse relacional escalonável e de alto desempenho baseado no SQL Server com a flexibilidade de um data lake e de um Apache Spark de código aberto. Ele também inclui suporte nativo para análise de log e telemetria com o Microsoft Fabric Real-Time Intelligence, bem como pipelines de dados integrados para ingestão de dados e transformação. Cada experiência de produto do Microsoft Fabric tem seu próprio ambiente, por exemplo, o Data Factory Home. Cada Fabric Home exibe os itens que você cria e tem permissão para usar em todos os espaços de trabalho que você acessa. O Microsoft Fabric é uma ótima escolha quando você deseja criar uma solução de análise única e unificada.

### Azure Databricks:
Uma implementação da popular plataforma Databricks no Azure. O Databricks é uma solução abrangente de análise de dados criada com base no Apache Spark e que oferece funcionalidades nativas de SQL, bem como clusters Spark otimizados para carga de trabalho para análise de dados e ciência de dados. O Databricks fornece uma interface interativa do usuário por meio da qual o sistema pode ser gerenciado e os dados podem ser explorados em notebooks interativos. Devido ao seu uso comum em várias plataformas de nuvem, pode ser interessante considerar a utilização do Azure Databricks como seu repositório analítico se quiser aproveitar a experiência já adquirida com essa plataforma, se precisar operar em um ambiente de várias nuvens ou oferecer suporte a uma solução portátil em nuvem.





## https://learn.microsoft.com/pt-br/training/modules/examine-components-of-modern-data-warehouse/4-analytical-data-stores
https://learn.microsoft.com/pt-br/training/paths/azure-data-fundamentals-explore-data-warehouse-analytics/